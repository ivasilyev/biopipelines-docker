#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import re
import argparse
import subprocess
import json


def parse_args():
    starting_parser = argparse.ArgumentParser(description="This script performs two bowtie/bowtie2-based alignments. For the second alignment it takes the non-mapped reads. REFDATA files are generated by the 'cook_the_reference' script")
    starting_parser.add_argument("-f", "--filter", required=True,
                                 help="(Optional) (Not for single alignment) Filtering DNA sequence REFDATA")
    starting_parser.add_argument("-c", "--coverage", required=True,
                                 help="DNA sequence REFDATA to calculate coverage")
    starting_parser.add_argument("-s", "--sampledata", required=True,
                                 help="Input list containing two tab-delimited columns for colorspace or non-colorspace sequences and three for paired-end sequences: sample name and absolute path(s). May contain a header")
    starting_parser.add_argument("-m", "--mask", default=None,
                                 help="(Optional) Mask to be added to resulting files. Automtically apended by both REFDATA file names")
    starting_parser.add_argument("-t", "--threads", default=None, type=int,
                                 help="(Optional) Number of CPU cores to use, maximal by default")
    starting_parser.add_argument("-n", "--no_coverage", default=False, action='store_true',
                                 help="(Optional) (Only for single alignment) If selected, cancels coverage extraction")
    starting_parser.add_argument("-o", "--output", required=True,
                                 help="Output directory")
    return starting_parser.parse_args()


def parse_namespace():
    namespace = parse_args()
    default_threads = int(subprocess.getoutput("nproc"))
    if not namespace.threads or default_threads < namespace.threads:
        namespace.threads = default_threads
    return namespace.filter, namespace.coverage, namespace.sampledata, namespace.mask, str(namespace.threads), namespace.no_coverage, namespace.output


def file_to_list(file):
    file_buffer = open(file, 'rU')
    output_list = [j for j in [re.sub('[\r\n]', '', i) for i in file_buffer] if len(j) > 0]
    file_buffer.close()
    return output_list


def external_route(input_direction_list):
    process = subprocess.Popen(input_direction_list, shell=False, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
    (output, error) = process.communicate()
    process.wait()
    if error:
        print(error)
    return output.decode("utf-8")


def rpush_sampledata(sampledata_line):
    sampledata_list = sampledata_line.split("\t")
    print("Pushing to queue: ", sampledata_list[0])
    # json example: {"filter": "", "coverage": "", "sampledata": {"sample_name": "", "sample_path": ""}, "mask": "", "threads": "", "output": ""}
    j = {"filter": filteringGenomeRefData, "coverage": coverageGenomeRefData, "sampledata": {"sample_name": sampledata_list[0], "sample_path": "\t".join(sampledata_list[1:])}, "mask": inputMask, "threads": cpuThreadsString, "output": outputDir}
    if noCoverageExtractionBool:
        j["no_coverage"] = True
    external_route(["redis-cli", "-h", "redis", "rpush", queueName, json.dumps(j)])


if __name__ == '__main__':
    filteringGenomeRefData, coverageGenomeRefData, sampleDataFileName, inputMask, cpuThreadsString, noCoverageExtractionBool, outputDir = parse_namespace()
    queueName = "bwt-filtering-pipeline-queue"
    print("Using queue name:", queueName)
    external_route(["redis-cli", "-h", "redis", "flushall"])
    rpush_counter_num = 0
    for sampledataLine in file_to_list(sampleDataFileName):
        rpush_sampledata(sampledataLine)
        rpush_counter_num += 1
    print("Created queue:")
    print(external_route(["redis-cli", "-h", "redis", "lrange", queueName, "0", "-1"]))
    print("\n\nCompleted filling the Redis queue '" + queueName + "' with " + str(rpush_counter_num) + " items.")
