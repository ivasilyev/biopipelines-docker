#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import re
import argparse
import json
import redis


def parse_args():
    starting_parser = argparse.ArgumentParser(description="This script performs two bowtie/bowtie2-based alignments. For the second alignment it takes the non-mapped reads. REFDATA files are generated by the 'cook_the_reference' script")
    starting_parser.add_argument("-r", "--refdata", required=True,
                                 help="DNA sequence REFDATA to calculate coverage")
    starting_parser.add_argument("-s", "--sampledata", required=True,
                                 help="Input list containing two tab-delimited columns for colorspace or non-colorspace sequences and three for paired-end sequences: sample name and absolute path(s). May contain a header")
    starting_parser.add_argument("-m", "--mask", default=None,
                                 help="(Optional) Mask to be added to resulting files. Automtically apended by both REFDATA file names")
    starting_parser.add_argument("-t", "--threads", default="max",
                                 help="(Optional) Number of CPU cores to use. Also may utilize 'max' (default), 'half', 'third' and 'two_thirds' of total available threads")
    starting_parser.add_argument("-n", "--no_coverage", default=False, action='store_true',
                                 help="(Optional) (Only for single alignment) If selected, cancels coverage extraction")
    starting_parser.add_argument("-o", "--output", required=True,
                                 help="Output directory")
    starting_parser.add_argument("-q", "--queue", required=True,
                                 help="Redis queue name")
    starting_parser.add_argument("-f", "--flush", default=False, action='store_true',
                                 help="Flush all Redis queues")
    return starting_parser.parse_args()


def parse_namespace():
    namespace = parse_args()
    return namespace.refdata, namespace.sampledata, namespace.mask, str(namespace.threads), namespace.no_coverage, namespace.output, namespace.queue, namespace.flush


def file_to_list(file):
    file_buffer = open(file, 'rU')
    output_list = [j for j in [re.sub('[\r\n]', '', i) for i in file_buffer] if len(j) > 0]
    file_buffer.close()
    return output_list


class RedisMQ(object):
    def __init__(self, name, **redis_kwargs):
        """The default connection parameters are: host='localhost', port=6379, db=0

        The work queue is identified by "name".  The library may create other
        keys with "name" as a prefix.
        """
        self._db = redis.StrictRedis(**redis_kwargs)
        self._main_q_key = name
        print("Connected to Redis DB queue: {}".format(self._main_q_key))

    def flushall(self):
        print("Flushed Redis DB: {}".format(self._db.flushdb()))

    def rpush(self, value):
        o = self._db.rpush(self._main_q_key, value)
        print("Item '{a}' pushed to queue '{b}' with number {c}".format(a=value, b=self._main_q_key, c=o))

    def disconnect(self):
        self._db.connection_pool.disconnect()


def rpush_sampledata(sampledata_line):
    sampledata_list = sampledata_line.split("\t")
    # json example: {"sampledata": {"sample_name": "", "sample_path": ""}, "filter": "", "coverage": "", "mask": "", "threads": "", "output": ""}
    j = {"sampledata": {"sample_name": sampledata_list[0],
                        "sample_path": "\t".join(sampledata_list[1:])},
         "refdata": refDataFileName,
         "mask": inputMask,
         "threads": cpuThreadsString,
         "output": outputDir}
    if noCoverageExtractionBool:
        j["no_coverage"] = True
    redisConnection.rpush(json.dumps(j))


if __name__ == '__main__':
    refDataFileName, sampleDataFileName, inputMask, cpuThreadsString, noCoverageExtractionBool, outputDir, queueName, resetBool = parse_namespace()
    redisConnection = RedisMQ(name=queueName, host="redis")
    if resetBool:
        redisConnection.flushall()
    rpush_counter_num = 0
    for sampledataLine in file_to_list(sampleDataFileName):
        rpush_sampledata(sampledataLine)
        rpush_counter_num += 1
    print("""
Completed filling the Redis queue '{}' with {} items
          """.format(queueName, str(rpush_counter_num)))
